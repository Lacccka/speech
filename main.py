# main.py
import asyncio
import sys
from pathlib import Path
from typing import Any, List, Optional

from pydub import AudioSegment

SRC_DIR = Path(__file__).resolve().parent / "src"
if str(SRC_DIR) not in sys.path:
    sys.path.insert(0, str(SRC_DIR))

from aiogram import Bot, Dispatcher, F
from aiogram.exceptions import TelegramBadRequest
from aiogram.filters import CommandStart
from aiogram.types import Message, FSInputFile

from db import (
    init_db,
    get_user,
    set_state,
    set_profile,
    start_user_session,
    add_sample,
    get_latest_samples,
    delete_user_samples,
)
from keyboards import main_kb
from audio_utils import (
    user_voice_dir,
    convert_to_wav,
    clear_user_voices,
    user_output_path,
    user_output_ogg_path,
    wav_to_ogg_opus,
)
from training import continue_training, train_new_voice
from tts_engine import assemble_segments, normalize_to_target, synthesize_ru

from speech.config import load_config
from speech.logging import configure_logging, get_logger

SAFE_TEXT_LENGTH = 250
DEFAULT_CHUNK_LENGTH = 180

TRAINING_STATE_NEW = "training_new"
TRAINING_STATE_CONTINUE = "training_continue"
TRAINING_STATE_SELECT = "training_select"

TRAINING_MODE_NEW_COMMANDS = {"–Ω–æ–≤–æ–µ –æ–±—É—á–µ–Ω–∏–µ", "–Ω–∞—á–∞—Ç—å –∑–∞–Ω–æ–≤–æ", "–Ω–æ–≤–æ–µ"}
TRAINING_MODE_CONTINUE_COMMANDS = {"–ø—Ä–æ–¥–æ–ª–∂–∏—Ç—å –æ–±—É—á–µ–Ω–∏–µ", "–¥–æ–æ–±—É—á–∏—Ç—å", "–ø—Ä–æ–¥–æ–ª–∂–∏—Ç—å"}


configure_logging()
logger = get_logger(__name__)
config = load_config()

bot = Bot(token=config.bot.token)
dp = Dispatcher()


def split_text_for_tts(text: str, max_chars: int = DEFAULT_CHUNK_LENGTH) -> List[str]:
    """
    –î–µ–ª–∏—Ç —Ç–µ–∫—Å—Ç –Ω–∞ —á–∞—Å—Ç–∏, —Å—Ç–∞—Ä–∞—è—Å—å –Ω–µ –ø—Ä–µ–≤—ã—à–∞—Ç—å max_chars –∏ –Ω–µ —Ä–∞–∑–±–∏–≤–∞—Ç—å —Å–ª–æ–≤–∞.
    """

    chunks: List[str] = []
    buffer: List[str] = []

    def flush_buffer() -> None:
        if buffer:
            combined = " ".join(buffer).strip()
            if combined:
                chunks.append(combined)
            buffer.clear()

    for paragraph in text.splitlines():
        paragraph = paragraph.strip()
        if not paragraph:
            flush_buffer()
            continue

        words = paragraph.split()
        for word in words:
            if not buffer:
                buffer.append(word)
                continue

            prospective = f"{' '.join(buffer)} {word}"
            if len(prospective) <= max_chars:
                buffer.append(word)
            else:
                flush_buffer()
                buffer.append(word)

    flush_buffer()

    if not chunks:
        stripped = text.strip()
        if stripped:
            return [stripped[:max_chars]]
        return []

    return chunks


def synthesize_with_splitting(
    text: str,
    profile_path: str,
    out_path: Path,
    *,
    language: Optional[str] = None,
    gpt_condition_length: Optional[int] = None,
    reference_duration: Optional[float] = None,
    **synthesis_kwargs: Any,
) -> None:
    """
    –í—ã–∑—ã–≤–∞–µ—Ç —Å–∏–Ω—Ç–µ–∑ —Å –¥—Ä–æ–±–ª–µ–Ω–∏–µ–º –¥–ª–∏–Ω–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ –∏ –æ–±—ä–µ–¥–∏–Ω—è–µ—Ç WAV-—Ñ–∞–π–ª—ã.
    """

    out_path.parent.mkdir(parents=True, exist_ok=True)

    chunks = split_text_for_tts(text)
    if not chunks:
        raise ValueError("–ü–µ—Ä–µ–¥–∞–Ω –ø—É—Å—Ç–æ–π —Ç–µ–∫—Å—Ç –¥–ª—è —Å–∏–Ω—Ç–µ–∑–∞")

    effective_language = language if language is not None else config.tts.language
    effective_gpt_condition_length = (
        gpt_condition_length
        if gpt_condition_length is not None
        else config.tts.gpt_conditioning_length
    )
    effective_reference_duration = (
        reference_duration
        if reference_duration is not None
        else config.tts.reference_duration
    )

    chunk_kwargs = dict(synthesis_kwargs)
    chunk_kwargs.setdefault("crossfade_ms", config.tts.chunk_crossfade_ms)
    chunk_kwargs.setdefault("target_dbfs", config.tts.chunk_target_dbfs)
    chunk_kwargs.setdefault("silence_threshold", config.tts.silence_threshold)
    chunk_kwargs.setdefault("silence_chunk_len", config.tts.silence_chunk_len)
    chunk_kwargs.setdefault("deesser_frequency", config.tts.deesser_frequency)
    chunk_kwargs.setdefault("deesser_reduction_db", config.tts.deesser_reduction_db)

    if len(chunks) == 1:
        synthesize_ru(
            chunks[0],
            profile_path,
            str(out_path),
            language=effective_language,
            gpt_cond_len=effective_gpt_condition_length,
            reference_duration=effective_reference_duration,
            **chunk_kwargs,
        )
        return

    temp_paths: List[Path] = []
    chunk_segments: List[AudioSegment] = []

    try:
        for idx, chunk in enumerate(chunks):
            temp_path = out_path.with_name(f"{out_path.stem}_part{idx}.wav")
            synthesize_ru(
                chunk,
                profile_path,
                str(temp_path),
                language=effective_language,
                gpt_cond_len=effective_gpt_condition_length,
                reference_duration=effective_reference_duration,
                **chunk_kwargs,
            )
            temp_paths.append(temp_path)
            chunk_segments.append(AudioSegment.from_wav(temp_path))

        effective_crossfade = chunk_kwargs["crossfade_ms"]
        combined = assemble_segments(
            chunk_segments,
            crossfade_ms=effective_crossfade,
        )
        combined = normalize_to_target(
            combined,
            target_dbfs=chunk_kwargs["target_dbfs"],
        )
        combined.export(out_path, format="wav")
    finally:
        for temp_path in temp_paths:
            temp_path.unlink(missing_ok=True)


@dp.message(CommandStart())
async def cmd_start(message: Message):
    await get_user(message.from_user.id)  # —Å–æ–∑–¥–∞—ë–º –∑–∞–ø–∏—Å—å –≤ –ë–î –µ—Å–ª–∏ –Ω–µ—Ç
    await message.answer(
        "–ü—Ä–∏–≤–µ—Ç! –Ø –±–æ—Ç –¥–ª—è –∫–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏—è –≥–æ–ª–æ—Å–∞.\n\n"
        "üîπ –ù–∞–∂–º–∏ ¬´üéô –ù–∞—á–∞—Ç—å –æ–±—É—á–µ–Ω–∏–µ¬ª –∏ –ø—Ä–∏—à–ª–∏ –Ω–µ—Å–∫–æ–ª—å–∫–æ –≥–æ–ª–æ—Å–æ–≤—ã—Ö.\n"
        "üîπ –û—Ç–ø—Ä–∞–≤—å 5‚Äì10 –≥–æ–ª–æ—Å–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π –¥–ª–∏–Ω–æ–π 5‚Äì10 —Å–µ–∫—É–Ω–¥, —á—Ç–æ–±—ã —è —Å–º–æ–≥ —Å–æ–±—Ä–∞—Ç—å –±–∞–∑–æ–≤—ã–π –ø—Ä–æ—Ñ–∏–ª—å.\n"
        "üîπ –ï—Å–ª–∏ –Ω—É–∂–Ω–æ –æ–±–Ω–æ–≤–∏—Ç—å –≥–æ–ª–æ—Å –ø–æ–∑–∂–µ ‚Äî –∏—Å–ø–æ–ª—å–∑—É–π –∫–æ–º–∞–Ω–¥—É ¬´–î–æ–æ–±—É—á–∏—Ç—å¬ª.\n"
        "üîπ –ü–æ—Ç–æ–º ¬´üõë –ó–∞–≤–µ—Ä—à–∏—Ç—å –æ–±—É—á–µ–Ω–∏–µ¬ª ‚Äî —è —Å–æ–±–µ—Ä—É –ø—Ä–æ—Ñ–∏–ª—å.\n"
        "üîπ –ü–æ—Ç–æ–º ¬´üó£ –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å¬ª –∏ –ø—Ä–∏—à–ª–∏ —Ç–µ–∫—Å—Ç ‚Äî —è –æ–∑–≤—É—á—É –µ–≥–æ —Ç–≤–æ–∏–º –≥–æ–ª–æ—Å–æ–º.\n\n"
        f"‚ÑπÔ∏è –û–¥–∏–Ω –∑–∞–ø—Ä–æ—Å ‚Äî –¥–æ {SAFE_TEXT_LENGTH} —Å–∏–º–≤–æ–ª–æ–≤ —Ç–µ–∫—Å—Ç–∞.",
        reply_markup=main_kb(),
    )


async def _enter_training_mode(message: Message, user_id: int, mode: str) -> None:
    session_id: int | None = None
    if mode == TRAINING_STATE_NEW:
        await delete_user_samples(user_id)
        clear_user_voices(user_id)
        session_id = await start_user_session(user_id)
        await set_state(user_id, TRAINING_STATE_NEW)
        await message.answer(
            "–Ø –æ—á–∏—Å—Ç–∏–ª –ø—Ä–µ–¥—ã–¥—É—â–∏–µ –∑–∞–ø–∏—Å–∏. –ü—Ä–∏—Å—ã–ª–∞–π –Ω–æ–≤—ã–µ –≥–æ–ª–æ—Å–æ–≤—ã–µ –ø–æ–¥—Ä—è–¥. –î–ª—è —Å—Ç–∞—Ä—Ç–æ–≤–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è –æ—Ç–ø—Ä–∞–≤—å —Ö–æ—Ç—è –±—ã 5‚Äì10"
            " —Å–æ–æ–±—â–µ–Ω–∏–π –¥–ª–∏–Ω–æ–π 5‚Äì10 —Å–µ–∫—É–Ω–¥, –∞ –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ–≥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ —Å–æ–±–µ—Ä–∏ 20‚Äì60 –º–∏–Ω—É—Ç —á–∏—Å—Ç—ã—Ö –∑–∞–ø–∏—Å–µ–π –æ–¥–Ω–∏–º –≥–æ–ª–æ—Å–æ–º:"
            " –∫–æ—Ä–æ—Ç–∫–∏–µ —Å–µ–≥–º–µ–Ω—Ç—ã –ø–æ 2‚Äì10 —Å–µ–∫—É–Ω–¥ –≤ –æ–¥–∏–Ω–∞–∫–æ–≤—ã—Ö —É—Å–ª–æ–≤–∏—è—Ö (—Ä–æ–≤–Ω–∞—è —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å, –±–µ–∑ —à—É–º–æ–≤, –æ–¥–∏–Ω –∏ —Ç–æ—Ç –∂–µ"
            " –º–∏–∫—Ä–æ—Ñ–æ–Ω). –ó–∞–ø–∏—Å–∏ –º–æ–∂–Ω–æ –Ω–∞–∫–∞–ø–ª–∏–≤–∞—Ç—å –∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø–æ–∑–∂–µ –¥–ª—è –¥–æ–æ–±—É—á–µ–Ω–∏—è."
            " –ö–æ–≥–¥–∞ –∑–∞–∫–æ–Ω—á–∏—à—å ‚Äî –Ω–∞–∂–º–∏ ¬´üõë –ó–∞–≤–µ—Ä—à–∏—Ç—å –æ–±—É—á–µ–Ω–∏–µ¬ª."
        )
    elif mode == TRAINING_STATE_CONTINUE:
        session_id = await start_user_session(user_id)
        await set_state(user_id, TRAINING_STATE_CONTINUE)
        await message.answer(
            "–ü—Ä–∏–Ω—è–ª —Ä–µ–∂–∏–º –¥–æ–æ–±—É—á–µ–Ω–∏—è. –ü—Ä–∏—Å—ã–ª–∞–π –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –≥–æ–ª–æ—Å–æ–≤—ã–µ ‚Äî —è –¥–æ–±–∞–≤–ª—é –∏—Ö –∫ —Ç–µ–º, —á—Ç–æ —É–∂–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã."
            " –õ—É—á—à–µ –≤—Å–µ–≥–æ –æ—Ç–ø—Ä–∞–≤–∏—Ç—å 5‚Äì10 –Ω–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π –ø–æ 5‚Äì10 —Å–µ–∫—É–Ω–¥, —á—Ç–æ–±—ã –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ø—Ä–æ—à–ª–æ –∑–∞–º–µ—Ç–Ω–µ–µ."
            " –ö–æ–≥–¥–∞ –∑–∞–∫–æ–Ω—á–∏—à—å ‚Äî –Ω–∞–∂–º–∏ ¬´üõë –ó–∞–≤–µ—Ä—à–∏—Ç—å –æ–±—É—á–µ–Ω–∏–µ¬ª."
        )
    else:
        logger.error("Unknown training mode %s for user %s", mode, user_id)
        return

    logger.info("Started training session %s for user %s", session_id, user_id)


def _has_saved_voices(user_id: int) -> bool:
    voice_dir = user_voice_dir(user_id)
    return any(voice_dir.glob("*.wav"))


@dp.message(F.text == "üéô –ù–∞—á–∞—Ç—å –æ–±—É—á–µ–Ω–∏–µ")
async def start_training(message: Message):
    user_id = message.from_user.id
    _, state, profile_path, _ = await get_user(user_id)

    if state in {TRAINING_STATE_NEW, TRAINING_STATE_CONTINUE}:
        await message.answer(
            "–Ø —É–∂–µ –∂–¥—É –≥–æ–ª–æ—Å–æ–≤—ã–µ. –û—Ç–ø—Ä–∞–≤—å –µ—â—ë –Ω–µ—Å–∫–æ–ª—å–∫–æ –∏–ª–∏ –Ω–∞–∂–º–∏ ¬´üõë –ó–∞–≤–µ—Ä—à–∏—Ç—å –æ–±—É—á–µ–Ω–∏–µ¬ª."
        )
        return

    if _has_saved_voices(user_id) or profile_path:
        await set_state(user_id, TRAINING_STATE_SELECT)
        await message.answer(
            "–£ —Ç–µ–±—è —É–∂–µ –µ—Å—Ç—å –∑–∞–ø–∏—Å–∏. –í—ã–±–µ—Ä–∏ —Ä–µ–∂–∏–º: –Ω–∞–ø–∏—à–∏ ¬´–ù–æ–≤–æ–µ –æ–±—É—á–µ–Ω–∏–µ¬ª, —á—Ç–æ–±—ã –Ω–∞—á–∞—Ç—å –∑–∞–Ω–æ–≤–æ (—Å—Ç–∞—Ä—ã–µ –∑–∞–ø–∏—Å–∏ —É–¥–∞–ª—é)"
            " –∏ —Å–Ω–æ–≤–∞ —Å–æ–±—Ä–∞—Ç—å 5‚Äì10 —Å—Ç–∞—Ä—Ç–æ–≤—ã—Ö –≥–æ–ª–æ—Å–æ–≤—ã—Ö, –∏–ª–∏ ¬´–î–æ–æ–±—É—á–∏—Ç—å¬ª/¬´–ü—Ä–æ–¥–æ–ª–∂–∏—Ç—å –æ–±—É—á–µ–Ω–∏–µ¬ª, —á—Ç–æ–±—ã –¥–æ–±–∞–≤–∏—Ç—å –Ω–æ–≤—ã–µ"
            " –æ–±—Ä–∞–∑—Ü—ã –∫ —É–∂–µ —Å–æ—Ö—Ä–∞–Ω—ë–Ω–Ω—ã–º."
        )
        return

    await _enter_training_mode(message, user_id, TRAINING_STATE_NEW)


@dp.message(F.voice)
async def handle_voice(message: Message):
    user_id = message.from_user.id
    _, state, _, current_session = await get_user(user_id)

    if state not in {TRAINING_STATE_NEW, TRAINING_STATE_CONTINUE}:
        await message.answer(
            "–°–µ–π—á–∞—Å —Ç—ã –Ω–µ –≤ —Ä–µ–∂–∏–º–µ –æ–±—É—á–µ–Ω–∏—è. –ù–∞–∂–º–∏ ¬´üéô –ù–∞—á–∞—Ç—å –æ–±—É—á–µ–Ω–∏–µ¬ª."
        )
        return

    # —Å–∫–∞—á–∏–≤–∞–µ–º –≥–æ–ª–æ—Å–æ–≤–æ–µ
    voice = message.voice
    logger.info(
        f"voice.file_id={voice.file_id}, voice.file_unique_id={voice.file_unique_id}"
    )

    if message.chat.type != "private" or message.forward_date:
        await message.answer(
            "–ü—Ä–∏—à–ª–∏ –≥–æ–ª–æ—Å, –∑–∞–ø–∏—Å–∞–Ω–Ω—ã–π –ø—Ä—è–º–æ —Å—é–¥–∞, –Ω–µ –ø–µ—Ä–µ—Å–ª–∞–Ω–Ω—ã–π."
        )
        return

    user_dir = user_voice_dir(user_id)
    ogg_path = user_dir / f"{voice.file_unique_id}.ogg"
    wav_path = user_dir / f"{voice.file_unique_id}.wav"

    try:
        await bot.download(voice, destination=ogg_path)
    except TelegramBadRequest as exc:
        logger.warning("Failed to download voice message: %s", exc)
        await message.answer("–ü–µ—Ä–µ—à–ª–∏ –≥–æ–ª–æ—Å –µ—â—ë —Ä–∞–∑")
        return

    if not ogg_path.exists():
        logger.error("Downloaded voice file not found at %s", ogg_path)
        await message.answer("–ü–µ—Ä–µ—à–ª–∏ –≥–æ–ª–æ—Å –µ—â—ë —Ä–∞–∑")
        return

    convert_to_wav(str(ogg_path), str(wav_path))
    ogg_path.unlink(missing_ok=True)

    await add_sample(user_id, str(wav_path), session_id=current_session)

    await message.answer("–ü—Ä–∏–Ω—è–ª –≥–æ–ª–æ—Å–æ–≤–æ–µ üëç")


@dp.message(F.text == "üõë –ó–∞–≤–µ—Ä—à–∏—Ç—å –æ–±—É—á–µ–Ω–∏–µ")
async def finish_training(message: Message):
    user_id = message.from_user.id
    _, state, _, current_session = await get_user(user_id)

    if state not in {TRAINING_STATE_NEW, TRAINING_STATE_CONTINUE}:
        await message.answer(
            "–°–µ–π—á–∞—Å –æ–±—É—á–µ–Ω–∏–µ –Ω–µ –∏–¥—ë—Ç. –°–Ω–∞—á–∞–ª–∞ –Ω–∞–∂–º–∏ ¬´üéô –ù–∞—á–∞—Ç—å –æ–±—É—á–µ–Ω–∏–µ¬ª –∏ –ø—Ä–∏—à–ª–∏ –≥–æ–ª–æ—Å–æ–≤—ã–µ."
        )
        return

    samples = await get_latest_samples(user_id, current_session) if current_session else []
    if not samples:
        await message.answer(
            "–Ø –Ω–µ –Ω–∞—à—ë–ª –∑–∞–ø–∏—Å–µ–π. –ü—Ä–∏—à–ª–∏ —Ö–æ—Ç—è –±—ã –æ–¥–Ω–æ –≥–æ–ª–æ—Å–æ–≤–æ–µ –≤ —Ä–µ–∂–∏–º–µ –æ–±—É—á–µ–Ω–∏—è."
        )
        return

    if state == TRAINING_STATE_NEW:
        merged = train_new_voice(user_id)
    else:
        merged = continue_training(user_id)

    if not merged:
        await message.answer(
            "–Ø –Ω–µ –Ω–∞—à—ë–ª –∑–∞–ø–∏—Å–µ–π. –ü—Ä–∏—à–ª–∏ —Ö–æ—Ç—è –±—ã –æ–¥–Ω–æ –≥–æ–ª–æ—Å–æ–≤–æ–µ –≤ —Ä–µ–∂–∏–º–µ –æ–±—É—á–µ–Ω–∏—è."
        )
        return

    await set_profile(user_id, merged)
    await set_state(user_id, "idle")

    await message.answer(
        "–ì–æ—Ç–æ–≤–æ! –Ø —Å–æ–±—Ä–∞–ª —Ç–≤–æ–π –≥–æ–ª–æ—Å. –¢–µ–ø–µ—Ä—å –Ω–∞–∂–º–∏ ¬´üó£ –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å¬ª –∏ –ø—Ä–∏—à–ª–∏ —Ç–µ–∫—Å—Ç."
    )


@dp.message(F.text == "üó£ –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å")
async def ask_text(message: Message):
    user_id = message.from_user.id
    await set_state(user_id, "generate")
    await message.answer(
        f"–ü—Ä–∏—à–ª–∏ —Ç–µ–∫—Å—Ç, –∫–æ—Ç–æ—Ä—ã–π –Ω—É–∂–Ω–æ –æ–∑–≤—É—á–∏—Ç—å —Ç–≤–æ–∏–º –≥–æ–ª–æ—Å–æ–º (–¥–æ {SAFE_TEXT_LENGTH} —Å–∏–º–≤–æ–ª–æ–≤ –∑–∞ –æ–¥–∏–Ω –∑–∞–ø—Ä–æ—Å)."
        " –ï—Å–ª–∏ –Ω—É–∂–Ω–æ –±–æ–ª—å—à–µ ‚Äî –æ—Ç–ø—Ä–∞–≤–ª—è–π –ø–æ —á–∞—Å—Ç—è–º –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–π –ø–æ—à–∞–≥–æ–≤—É—é –≥–µ–Ω–µ—Ä–∞—Ü–∏—é."
    )


@dp.message(F.text)
async def handle_text(message: Message):
    user_id = message.from_user.id
    user_id, state, profile_path, _ = await get_user(user_id)

    if state == TRAINING_STATE_SELECT:
        text = (message.text or "").casefold()
        if text in TRAINING_MODE_NEW_COMMANDS:
            await _enter_training_mode(message, user_id, TRAINING_STATE_NEW)
        elif text in TRAINING_MODE_CONTINUE_COMMANDS:
            await _enter_training_mode(message, user_id, TRAINING_STATE_CONTINUE)
        else:
            await message.answer(
                "–ù–µ –ø–æ–Ω—è–ª —Ä–µ–∂–∏–º. –ù–∞–ø–∏—à–∏ ¬´–ù–æ–≤–æ–µ –æ–±—É—á–µ–Ω–∏–µ¬ª –∏–ª–∏ ¬´–ü—Ä–æ–¥–æ–ª–∂–∏—Ç—å –æ–±—É—á–µ–Ω–∏–µ¬ª."
            )
        return

    # —Ä–µ–∞–≥–∏—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –≤ —Ä–µ–∂–∏–º–µ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
    if state != "generate":
        return

    if not profile_path:
        await message.answer(
            "–£ —Ç–µ–±—è –Ω–µ—Ç –ø—Ä–æ—Ñ–∏–ª—è –≥–æ–ª–æ—Å–∞. –°–Ω–∞—á–∞–ª–∞ –æ–±—É—á–∏ –º–µ–Ω—è –≥–æ–ª–æ—Å–æ–≤—ã–º–∏."
        )
        await set_state(user_id, "idle")
        return

    text = message.text.strip()
    if not text:
        await message.answer(
            f"–¢–µ–∫—Å—Ç –ø—É—Å—Ç–æ–π ü§î –ü—Ä–∏—à–ª–∏ –Ω–æ—Ä–º–∞–ª—å–Ω—ã–π —Ç–µ–∫—Å—Ç –¥–æ {SAFE_TEXT_LENGTH} —Å–∏–º–≤–æ–ª–æ–≤."
        )
        return

    if len(text) > SAFE_TEXT_LENGTH:
        await message.answer(
            "–°–æ–æ–±—â–µ–Ω–∏–µ —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω–æ–µ –¥–ª—è –±–µ–∑–æ–ø–∞—Å–Ω–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏."
            f" –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —Å–æ–∫—Ä–∞—Ç–∏ –µ–≥–æ –¥–æ {SAFE_TEXT_LENGTH} —Å–∏–º–≤–æ–ª–æ–≤"
            " –∏–ª–∏ –∑–∞–ø—É—Å—Ç–∏ –ø–æ—à–∞–≥–æ–≤—É—é –≥–µ–Ω–µ—Ä–∞—Ü–∏—é, –æ—Ç–ø—Ä–∞–≤–ª—è—è —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ."
        )
        return

    out_path = user_output_path(user_id)
    ogg_path = user_output_ogg_path(user_id)
    await message.answer(
        "–ì–µ–Ω–µ—Ä–∏—Ä—É—é... –ü–æ–º–Ω–∏, —á—Ç–æ –ª—É—á—à–µ –¥–µ—Ä–∂–∞—Ç—å –æ—Ç–¥–µ–ª—å–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã –≤ –ø—Ä–µ–¥–µ–ª–∞—Ö –¥–æ–ø—É—Å—Ç–∏–º–æ–π –¥–ª–∏–Ω—ã."
    )

    # —Å–∏–Ω—Ç–µ–∑
    synthesize_with_splitting(text, profile_path, out_path)

    try:
        wav_to_ogg_opus(str(out_path), str(ogg_path))
    except Exception:
        logger.exception("Failed to convert WAV to OGG/Opus via ffmpeg")
        await message.answer("–Ω–µ —Å–º–æ–≥ –ø–µ—Ä–µ–∫–æ–¥–∏—Ä–æ–≤–∞—Ç—å –∞—É–¥–∏–æ, –ø—Ä–æ–≤–µ—Ä—å ffmpeg/libopus")
        await set_state(user_id, "idle")
        return

    voice_file = FSInputFile(str(ogg_path), filename="voice.ogg")
    await message.answer_voice(voice_file)

    # –≤–µ—Ä–Ω—ë–º –≤ –æ–±—ã—á–Ω—ã–π —Ä–µ–∂–∏–º
    await set_state(user_id, "idle")


async def main():
    await init_db()
    logger.info("Starting Telegram bot polling")
    await dp.start_polling(bot)


if __name__ == "__main__":
    asyncio.run(main())
