# Требования к данным

## Требования к данным
- Соберите от 20 до 60 минут чистых записей одного диктора, чтобы обеспечить устойчивое качество профиля и покрыть широкий спектр речевых интонаций.
- Разбейте материал на сегменты длительностью 2–10 секунд: это ускоряет подготовку, облегчает балансировку и позволяет гибко переиспользовать наборы.
- Поддерживайте одинаковые условия записи — одно и то же помещение, микрофон и расстояние до него, отсутствие фонового шума и ровный уровень громкости.
- Наращивайте датасет постепенно: сохранённые сегменты можно объединять при последующем дообучении без деградации качества.

## Форматы аудио
- **Входные данные:** голосовые сообщения пользователей принимаются в формате OGG/Opus (стандартный формат Telegram voice). Файлы автоматически конвертируются в WAV перед обработкой.
- **Промежуточный формат:** все фрагменты сохраняются в WAV (моно или стерео, 16-bit PCM).
- **Выходные данные:** результирующие профили и сгенерированная речь выдаются в WAV.

## Частоты дискретизации
- Входные голосовые сообщения могут иметь частоту от 16 кГц до 48 кГц. При конвертации сохраняется исходная частота.
- Итоговые профили и синтезированная речь сохраняются с той же частотой, что и исходные образцы. Для унификации вывода допускается постобработка и ресемплинг до 24 кГц при необходимости.

## Дополнительные рекомендации
- Избегайте фонового шума и резких перепадов громкости; система нормализует уровни, но сильные артефакты снижают качество профиля.
- Отправляйте несколько коротких сообщений вместо одного длинного: это ускоряет обработку и повышает устойчивость модели к вариативности речи.
- Соблюдайте требования к объёму и условиям из раздела «Требования к данным»: фиксируйте дату, оборудование и окружение, чтобы при объединении накопленных сегментов для дообучения не потерять контроль качества.

## Подготовка корпусов
- Для обучения и дообучения модели поддерживаются общедоступные корпуса LibriSpeech и Mozilla Common Voice. Используйте скрипты из `src/speech/data/datasets.py`, чтобы скачать необходимые сплиты с автоматическим кэшированием.
- Пример запуска: `PYTHONPATH=src python -m speech.data.datasets --dataset librispeech --split train.clean.100 --cache-dir ./data/cache` (скрипт использует HuggingFace `datasets`, а при отсутствии — `torchaudio`).

## Препроцессинг аудио
- Пайплайн нормализации, выравнивания громкости, обрезки тишины и сохранения спектрограмм реализован в `src/speech/data/transforms.py`.
- Для настройки каталогов и конфигураций воспользуйтесь утилитами из `src/speech/data/utils.py`. Файл манифеста и спектрограммы будут сохранены в указанные пути, если они существуют или могут быть созданы.
